{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e36fc4",
   "metadata": {},
   "source": [
    "# CIFAR 10 image recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9f04d",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386f821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd326a5",
   "metadata": {},
   "source": [
    "# Getting and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate transforms for training (with augmentation) and test/validation (no augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),                                   # Random crop with padding (32x32 images)\n",
    "    transforms.RandomHorizontalFlip(),                                      # 50% chance of horizontal flip\n",
    "    transforms.ToTensor(),                                                  # scaling to [0, 1]\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                  # scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                                                  # scaling to [0, 1]\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                  # scaling to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65928b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 40000\n",
      "Validation set size: 10000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Downloads data if not already present, and loads it as a PyTorch dataset\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "# Split training set into train and validation (80-20) randomly (every class should be represented in both sets due to large amount of data)\n",
    "train_size = int(0.8 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "trainset, valset = torch.utils.data.random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training set size: {train_size}\")\n",
    "print(f\"Validation set size: {val_size}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment train and validation sets with the appropriate transforms (train gets augmentation, val gets no augmentation)\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=train_transform)\n",
    "val_dataset = torchvision.datasets.CIFAR10(root='./data',train=True,download=False, transform=test_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=test_transform)\n",
    "\n",
    "trainset = torch.utils.data.Subset(train_dataset, trainset.indices)\n",
    "valset = torch.utils.data.Subset(val_dataset, valset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2382a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "\n",
      "torch.Size([3, 32, 32])\n",
      "\n",
      "tensor(-1.) tensor(1.)\n",
      "\n",
      "tensor([[[-0.0588, -0.0745,  0.0196,  ..., -0.8745, -0.8039, -1.0000],\n",
      "         [-0.0510, -0.0196,  0.0196,  ..., -0.7020, -0.7412, -1.0000],\n",
      "         [-0.4118, -0.3176, -0.1922,  ..., -0.5373, -0.6078, -1.0000],\n",
      "         ...,\n",
      "         [ 0.1843,  0.6941,  0.3333,  ...,  0.3176,  0.3882, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-0.3412, -0.3412, -0.2627,  ..., -0.9451, -0.8118, -1.0000],\n",
      "         [-0.3333, -0.3176, -0.2941,  ..., -0.8431, -0.8039, -1.0000],\n",
      "         [-0.6314, -0.5529, -0.4745,  ..., -0.7490, -0.7490, -1.0000],\n",
      "         ...,\n",
      "         [-0.0745,  0.4431,  0.0980,  ...,  0.0118,  0.1294, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "        [[-0.6078, -0.6078, -0.5451,  ..., -1.0000, -0.8353, -1.0000],\n",
      "         [-0.6235, -0.6078, -0.6078,  ..., -0.9686, -0.8667, -1.0000],\n",
      "         [-0.8196, -0.7882, -0.7490,  ..., -0.9137, -0.8353, -1.0000],\n",
      "         ...,\n",
      "         [-0.3412,  0.0980, -0.1843,  ..., -0.2627, -0.0902, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "classes = train_dataset.classes\n",
    "img, label = train_dataset[0]\n",
    "print(\"Classes:\", classes)\n",
    "print()\n",
    "print(img.shape)\n",
    "print()\n",
    "print(torch.min(img), torch.max(img))\n",
    "print()\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf720cc5",
   "metadata": {},
   "source": [
    "## Definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f1cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a convolutional neural network for image classification\n",
    "# The network must have 3 input neurons, corresponding to the 3 color channels (RGB) of the input images\n",
    "# The network must have 10 output neurons, corresponding to the 10 classes in the CIFAR-10 dataset\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(24, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv1 -> relu -> pool -> conv2 -> relu -> pool -> conv3 -> relu -> flatten -> fc1 -> relu -> fc2\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # (3, 32, 32) -> (16, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # (16, 16, 16) -> (24, 8, 8)\n",
    "        x = F.relu(self.conv3(x))              # (24, 8, 8) -> (32, 8, 8)\n",
    "        x = torch.flatten(x, 1)                # (batch, 2048)\n",
    "        x = F.relu(self.fc1(x))                # (batch, 2048) -> (batch, 256)\n",
    "        x = self.fc2(x)                        # (batch, 256) -> (batch, 10)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40eaa0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df8e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "patience = 2                # number of epochs with validation loss smaller than best_val_loss required for early stopping\n",
    " \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()                                         # best for multi-class classification problems\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/16]\n",
      "Train Loss: 1.6253, Train Accuracy: 0.4037\n",
      "Val Loss:   1.2784, Val Accuracy:   0.5316\n",
      "--------------------------------------------------\n",
      "Epoch [2/16]\n",
      "Train Loss: 1.3056, Train Accuracy: 0.5256\n",
      "Val Loss:   1.1196, Val Accuracy:   0.5949\n",
      "--------------------------------------------------\n",
      "Epoch [3/16]\n",
      "Train Loss: 1.1672, Train Accuracy: 0.5806\n",
      "Val Loss:   1.0064, Val Accuracy:   0.6360\n",
      "--------------------------------------------------\n",
      "Epoch [4/16]\n",
      "Train Loss: 1.0682, Train Accuracy: 0.6187\n",
      "Val Loss:   0.9496, Val Accuracy:   0.6638\n",
      "--------------------------------------------------\n",
      "Epoch [5/16]\n",
      "Train Loss: 0.9962, Train Accuracy: 0.6454\n",
      "Val Loss:   0.9179, Val Accuracy:   0.6738\n",
      "--------------------------------------------------\n",
      "Epoch [6/16]\n",
      "Train Loss: 0.9509, Train Accuracy: 0.6615\n",
      "Val Loss:   0.8612, Val Accuracy:   0.7024\n",
      "--------------------------------------------------\n",
      "Epoch [7/16]\n",
      "Train Loss: 0.9084, Train Accuracy: 0.6797\n",
      "Val Loss:   0.8402, Val Accuracy:   0.7072\n",
      "--------------------------------------------------\n",
      "Epoch [8/16]\n",
      "Train Loss: 0.8839, Train Accuracy: 0.6871\n",
      "Val Loss:   0.8480, Val Accuracy:   0.7012\n",
      "--------------------------------------------------\n",
      "Epoch [9/16]\n",
      "Train Loss: 0.8545, Train Accuracy: 0.6992\n",
      "Val Loss:   0.7998, Val Accuracy:   0.7217\n",
      "--------------------------------------------------\n",
      "Epoch [10/16]\n",
      "Train Loss: 0.8363, Train Accuracy: 0.7044\n",
      "Val Loss:   0.7705, Val Accuracy:   0.7341\n",
      "--------------------------------------------------\n",
      "Epoch [11/16]\n",
      "Train Loss: 0.8110, Train Accuracy: 0.7117\n",
      "Val Loss:   0.7756, Val Accuracy:   0.7303\n",
      "--------------------------------------------------\n",
      "Epoch [12/16]\n",
      "Train Loss: 0.7983, Train Accuracy: 0.7169\n",
      "Val Loss:   0.7530, Val Accuracy:   0.7394\n",
      "--------------------------------------------------\n",
      "Epoch [13/16]\n",
      "Train Loss: 0.7772, Train Accuracy: 0.7237\n",
      "Val Loss:   0.7448, Val Accuracy:   0.7435\n",
      "--------------------------------------------------\n",
      "Epoch [14/16]\n",
      "Train Loss: 0.7638, Train Accuracy: 0.7307\n",
      "Val Loss:   0.7395, Val Accuracy:   0.7449\n",
      "--------------------------------------------------\n",
      "Epoch [15/16]\n",
      "Train Loss: 0.7467, Train Accuracy: 0.7360\n",
      "Val Loss:   0.7532, Val Accuracy:   0.7449\n",
      "--------------------------------------------------\n",
      "Epoch [16/16]\n",
      "Train Loss: 0.7437, Train Accuracy: 0.7390\n",
      "Val Loss:   0.7492, Val Accuracy:   0.7453\n",
      "--------------------------------------------------\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_epoch_loss = val_loss / len(valloader)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.4f}\")\n",
    "    print(f\"Val Loss:   {val_epoch_loss:.4f}, Val Accuracy:   {val_epoch_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if val_epoch_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22466cb1",
   "metadata": {},
   "source": [
    "## Testing on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c9b4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS\n",
      "\n",
      "Test Loss: 0.7445\n",
      "Test Accuracy: 0.7411 (7411/10000)\n",
      "\n",
      "Confusion Matrix:\n",
      "            airplane  automobile  bird  cat  deer  dog  frog  horse  ship  \\\n",
      "airplane         789          39    60   10    12    0    10      5    39   \n",
      "automobile        13         891     6    3     1    1     5      1     6   \n",
      "bird              60          11   665   31    76   51    63     25     6   \n",
      "cat               24          19    85  544    65  113    88     34     8   \n",
      "deer              25           4    69   29   745   19    58     47     3   \n",
      "dog               15           9    80  178    62  553    41     48     7   \n",
      "frog               3           6    53   42    30   11   843      4     5   \n",
      "horse             19           4    42   23    53   41     7    793     2   \n",
      "ship              93          63    18    9     6    5     7      3   764   \n",
      "truck             35          95     8    5     4    3     9      7    10   \n",
      "\n",
      "            truck  \n",
      "airplane       36  \n",
      "automobile     73  \n",
      "bird           12  \n",
      "cat            20  \n",
      "deer            1  \n",
      "dog             7  \n",
      "frog            3  \n",
      "horse          16  \n",
      "ship           32  \n",
      "truck         824  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_accuracy = correct / total\n",
    "test_loss = test_loss / len(testloader)\n",
    "\n",
    "print(\"TEST RESULTS\")\n",
    "print()\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({correct}/{total})\")\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3078e66",
   "metadata": {},
   "source": [
    "## Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08e6c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Class Accuracy:\n",
      "-----------------------------------\n",
      "airplane       :  78.90% (789/1000)\n",
      "automobile     :  89.10% (891/1000)\n",
      "bird           :  66.50% (665/1000)\n",
      "cat            :  54.40% (544/1000)\n",
      "deer           :  74.50% (745/1000)\n",
      "dog            :  55.30% (553/1000)\n",
      "frog           :  84.30% (843/1000)\n",
      "horse          :  79.30% (793/1000)\n",
      "ship           :  76.40% (764/1000)\n",
      "truck          :  82.40% (824/1000)\n"
     ]
    }
   ],
   "source": [
    "# Per-class accuracy\n",
    "class_correct = {str(i): 0 for i in range(10)}\n",
    "class_total = {str(i): 0 for i in range(10)}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            label = str(labels[i].item())\n",
    "            class_total[label] += 1\n",
    "            if predicted[i] == labels[i]:\n",
    "                class_correct[label] += 1\n",
    "\n",
    "print(\"Per-Class Accuracy:\")\n",
    "print(\"-\" * 35)\n",
    "for i in range(10):\n",
    "    if class_total[str(i)] > 0:\n",
    "        acc = 100 * class_correct[str(i)] / class_total[str(i)]\n",
    "        print(f\"{classes[i]:15s}: {acc:6.2f}% ({class_correct[str(i)]}/{class_total[str(i)]})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
